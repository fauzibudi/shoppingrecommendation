{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b8dff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_col: instruction | a_col: response\n",
      "Rows kept: 26872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 840/840 [59:54<00:00,  4.28s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully embedded and wrote 26872 documents to MongoDB Atlas.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "import dotenv\n",
    "from haystack import Pipeline, Document\n",
    "from haystack.components.embedders import SentenceTransformersDocumentEmbedder\n",
    "from haystack.components.writers import DocumentWriter\n",
    "from haystack_integrations.document_stores.mongodb_atlas import MongoDBAtlasDocumentStore\n",
    "from haystack.utils import Secret\n",
    "from haystack.components.preprocessors import RecursiveDocumentSplitter\n",
    "from haystack.document_stores.types import DuplicatePolicy\n",
    "from getpass import getpass\n",
    "\n",
    "# Section 1: Data Loading and Preprocessing\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "DATA_PATH = '../data/Bitext_Sample_Customer_Support_Training_Dataset_27K_responses-v11.csv'\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "QUESTION_CANDIDATES = ['instruction', 'intent', 'question', 'Question', 'text', 'query', 'prompt', 'utterance']\n",
    "ANSWER_CANDIDATES = ['response', 'answer', 'Answer', 'Response', 'reply']\n",
    "\n",
    "def pick_col(cols, candidate):\n",
    "    for c in candidate:\n",
    "        if c in cols:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "def clean_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = str(text).replace(\"\\\\r\", \" \").replace(\"\\\\n\", \" \").replace(\"\\\\t\", \" \").replace(\"\\\\xa0\", \" \").strip()\n",
    "    return \" \".join(text.split())\n",
    "\n",
    "docs_raw = []\n",
    "if df is not None:\n",
    "    q_col = pick_col(df.columns, QUESTION_CANDIDATES) or \"instruction\"\n",
    "    a_col = pick_col(df.columns, ANSWER_CANDIDATES) or \"response\"\n",
    "    print(\"q_col:\", q_col, \"| a_col:\", a_col)\n",
    "\n",
    "    use_cols = [c for c in [\"instruction\", \"response\", \"intent\", \"category\", \"flags\"] if c in df.columns]\n",
    "    df_use = df[use_cols].copy()\n",
    "\n",
    "    for c in [\"instruction\", \"response\", \"intent\", \"category\"]:\n",
    "        if c in df_use.columns:\n",
    "            df_use[c] = df_use[c].apply(clean_text)\n",
    "\n",
    "    if \"instruction\" in df_use.columns and \"intent\" in df_use.columns:\n",
    "        empty_instr = df_use[\"instruction\"] == \"\"\n",
    "        df_use.loc[empty_instr, \"instruction\"] = df_use.loc[empty_instr, \"intent\"]\n",
    "\n",
    "    mask_valid = (df_use.get(\"instruction\", \"\") != \"\") & (df_use.get(\"response\", \"\") != \"\")\n",
    "    df_use = df_use[mask_valid].drop_duplicates(subset=[\"instruction\", \"response\"]).reset_index(drop=True)\n",
    "    print(\"Rows kept:\", len(df_use))\n",
    "\n",
    "    for i, row in df_use.iterrows():\n",
    "        q = row.get(\"instruction\", \"\")\n",
    "        a = row.get(\"response\", \"\")\n",
    "        text = f\"Q: {q}\\\\nA: {a}\"\n",
    "        meta = {\n",
    "            \"row_id\": int(i),\n",
    "            \"source\": DATA_PATH.name if isinstance(DATA_PATH, Path) else str(DATA_PATH),\n",
    "            \"category\": row.get(\"category\", \"\"),\n",
    "            \"intent\": row.get(\"intent\", \"\"),\n",
    "        }\n",
    "        docs_raw.append({\"content\": text, \"metadata\": meta})\n",
    "\n",
    "documents = [Document(content=doc[\"content\"], meta=doc[\"metadata\"]) for doc in docs_raw]\n",
    "\n",
    "\n",
    "\n",
    "# Section 2: MongoDB Atlas Setup\n",
    "\n",
    "\n",
    "os.environ[\"MONGO_CONNECTION_STRING\"] = os.getenv(\"MONGO_CONNECTION_STRING2\")\n",
    "\n",
    "document_store = MongoDBAtlasDocumentStore(\n",
    "    database_name=\"depato_store\",\n",
    "    collection_name=\"common_info\",\n",
    "    vector_search_index=\"vector_index\",\n",
    "    full_text_search_index=\"search_index\",\n",
    ")\n",
    "\n",
    "# Section 3: Haystack Pipeline\n",
    "\n",
    "pipeline = Pipeline()\n",
    "pipeline.add_component(\"embedder\", SentenceTransformersDocumentEmbedder())\n",
    "pipeline.add_component(\"writer\", DocumentWriter(document_store=document_store, policy=DuplicatePolicy.OVERWRITE))\n",
    "pipeline.connect(\"embedder\", \"writer\")\n",
    "\n",
    "pipeline.run({\n",
    "    \"embedder\": {\n",
    "        \"documents\": documents\n",
    "    }\n",
    "})\n",
    "\n",
    "print(f\"Successfully embedded and wrote {len(documents)} documents to MongoDB Atlas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67879114",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
